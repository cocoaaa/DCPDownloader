{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60eae05",
   "metadata": {},
   "source": [
    "20221024-173245\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e11d62",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d29db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37917257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "sys.dont_write_bytecode = True\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b5508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any,List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable, TypeVar\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a54471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for webcrawling\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29931442",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import ReprLearn and TileMani packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reprlearn as rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprlearn.visualize.utils import get_fig, show_timg, show_timgs, show_npimgs, show_batch, make_grid_from_tensors\n",
    "from reprlearn.utils.misc import info, now2str, today2str, get_next_version_path, n_iter_per_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57423c12",
   "metadata": {},
   "source": [
    "## Path to data root dirs\n",
    "- DATA_ROOT: \n",
    "  - Use '/data/hayley-old/Tenanbaum2000/data' for MNIST, Mono-MNIST, Rotated-MNIST, Teapots\n",
    "  - Use `/data/hayley-old/maptiles_v2' folder for Maptile dataset\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT = Path(\"/data/hayley-old/Tenanbaum2000\")\n",
    "# DATA_ROOT = Path(\"/data/hayley-old/Tenanbaum2000/data\")\n",
    "# MAP_DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "\n",
    "data_root = Path(\"/data/datasets\")\n",
    "real_data_dir = Path(\"/data/datasets/reverse-eng-data/originals/CelebA/img_align_celeba\")\n",
    "print(\"data_root: \", str(data_root))\n",
    "print(\"real_data_root  (original celeba): \", str(real_data_dir))\n",
    "print(real_data_dir.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee92e0",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(url):\n",
    "    \"\"\"\n",
    "    Checks whether `url` is a valid URL.\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.netloc) and bool(parsed.scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4246738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: \n",
    "urlparse(url) \n",
    "# netloc: domain name\n",
    "# scheme: protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4ba89",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fdfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report:\n",
    "    def __init__(self, vid: int):\n",
    "        self.vid = vid\n",
    "        self.report_url = f'https://confluence.org/confluence.php?visitid={vid}'\n",
    "        self.img_page_url = f'https://confluence.org/photo.php?visitid={vid}&pic=ALL'\n",
    "        self.lat = None\n",
    "        self.lng = None\n",
    "        self.visit_idx = None\n",
    "        self.img_urls = []\n",
    "        self.text = ''\n",
    "        self.year = None\n",
    "        self.country = ''\n",
    "        \n",
    "        self.update_metadata()\n",
    "\n",
    "    \n",
    "    def update_metadata(self) -> None:\n",
    "        #parse html: get last,lng,text descr, year,country\n",
    "        # get hrml content of url\n",
    "        r = requests.get(self.report_url)\n",
    "        soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        # parse html \n",
    "#         lat = \n",
    "        pass\n",
    "    \n",
    "    def download_imgs(self, out_dir: Path) -> None:\n",
    "        \"\"\"Effect: sets self.img_urls, download image to out_dir\n",
    "        \"\"\"\n",
    "        pass\n",
    "    def download_imgs(self,\n",
    "                  out_dir: Path,\n",
    "                 filter_func: Optional[Callable]=None, \n",
    "                 verbose: bool=False) -> None:\n",
    "        \"\"\"Effect: sets self.img_urls, download image to out_dir\n",
    "        \"\"\"\n",
    "        # get hrml content of url\n",
    "        r = requests.get(self.img_page_url)\n",
    "        # parse html \n",
    "        soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "\n",
    "        \n",
    "        img_tags = soup.find_all(\"img\")\n",
    "\n",
    "        img_urls = [] \n",
    "        for img_tag in img_tags:\n",
    "            img_alt = img_tag.attrs.get(\"alt\")\n",
    "            img_url = img_tag.attrs.get(\"src\")\n",
    "            if not img_url:\n",
    "                continue\n",
    "\n",
    "            # concat to get full address to the image\n",
    "            img_url = urljoin(url, img_url)\n",
    "            # remove error-prone http get kvey-values in the url\n",
    "            try:\n",
    "                pos = img_url.index(\"?\")\n",
    "                img_url = img_url[:pos]\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            # check if img_url is valid and pass filter_func\n",
    "            if filter_func is not None and not filter_func(img_url, img_alt):\n",
    "                breakpoint()\n",
    "                print(f'{img_url} does not pass the filter function') #todo: write to a log file\n",
    "                continue\n",
    "\n",
    "            # download img_url\n",
    "            suffix = Path(img_url).suffix\n",
    "            filename = self.create_filename(img_alt, suffix) #{vid}-{lat}-{lon}-{direction}.jpg'\n",
    "            print('Downlaoding: ', img_url)\n",
    "            download(img_url, out_dir, filename)\n",
    "\n",
    "            # collect all img_urls\n",
    "            img_urls.append(img_url)\n",
    "            if verbose:\n",
    "                print(f'\\n {img_url}')\n",
    "\n",
    "        self.img_urls = img_urls\n",
    "        print('Done downloading imgs for ', self.vid)\n",
    "\n",
    "    \n",
    "    \n",
    "    def create_filename(self, img_alt: str, suffix: str) -> str:\n",
    "#         img_alt = img_alt.lower().replace(' ', '-')\n",
    "        return f'{self.vid}-{self.lat}-{self.lng}-{img_alt}{suffix}' \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://confluence.org/confluence.php?visitid=22761'\n",
    "\n",
    "\n",
    "# content of url\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03209eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = soup.find_all(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ba91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_urls(url: str, \n",
    "                 filter_func: Optional[Callable]=None, \n",
    "                 verbose: bool=False) -> List:\n",
    "    # content of url\n",
    "    r = requests.get(url)\n",
    "    # parse html \n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    imgs = soup.find_all(\"img\")\n",
    "    \n",
    "    img_urls = [] \n",
    "    for img_tag in imgs:\n",
    "        img_alt = img_tag.attrs.get(\"alt\")\n",
    "        img_url = img_tag.attrs.get(\"src\")\n",
    "        if not img_url:\n",
    "            continue\n",
    "\n",
    "        # concat to get full address to the image\n",
    "        img_url = urljoin(url, img_url)\n",
    "        # remove error-prone http get kvey-values in the url\n",
    "        try:\n",
    "            pos = img_url.index(\"?\")\n",
    "            img_url = img_url[:pos]\n",
    "        except ValueError:\n",
    "            pass\n",
    "        # check if img_url is valid and pass filter_func\n",
    "        if not is_valid(img_url):\n",
    "            continue\n",
    "        if filter_func is not None and not filter_func(img_url):\n",
    "            print('img_url does not pass the filter function')\n",
    "            continue\n",
    "\n",
    "        img_urls.append(img_url)\n",
    "        if verbose:\n",
    "            print()\n",
    "            print(img_tag)\n",
    "            print(img_url)\n",
    "    return img_urls\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda51482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, dirpath: Path, out_bn: Optional[str]=None):\n",
    "    \"\"\"Downloads a file given an URL and puts it in the folder `pathname`\n",
    "    \"\"\"\n",
    "    # if path doesn't exist, make that path dir\n",
    "    if not dirpath.exists():\n",
    "        dirpath.mkdir(parents=True)\n",
    "        print('Created: ', dirpath)\n",
    "        \n",
    "    # download the body of response by chunk, not immediately\n",
    "    response = requests.get(url, stream=True)\n",
    "    # get the total file size\n",
    "    file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "    # get the file name\n",
    "    out_bn = out_bn or  url.split(\"/\")[-1]\n",
    "    out_fn = dirpath / out_bn\n",
    "    # progress bar, changing the unit to bytes instead of iteration (default by tqdm)\n",
    "    progress = tqdm(response.iter_content(1024), f\"Downloading {out_fn}\", total=file_size, unit=\"B\", unit_scale=True, unit_divisor=1024)\n",
    "    with open(out_fn, \"wb\") as f:\n",
    "        for data in progress.iterable:\n",
    "            # write data read to the file\n",
    "            f.write(data)\n",
    "            # update the progress bar manually\n",
    "            progress.update(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e566e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filename(lat:str, lng: str, vid: str, img_alt:str, suffix: str):\n",
    "    img_alt = img_alt.lower().replace(' ', '-')\n",
    "    return f'{vid}-{lat}-{lng}-{img_alt}{suffix}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70790ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_imgs(url: str, \n",
    "                  out_dir: Path,\n",
    "                 filter_func: Optional[Callable]=None, \n",
    "                 verbose: bool=False) -> List:\n",
    "    # content of url\n",
    "    r = requests.get(url)\n",
    "    # parse html \n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    img_tags = soup.find_all(\"img\")\n",
    "    \n",
    "    img_urls = [] \n",
    "    for img_tag in img_tags:\n",
    "        img_alt = img_tag.attrs.get(\"alt\")\n",
    "        img_url = img_tag.attrs.get(\"src\")\n",
    "        if not img_url:\n",
    "            continue\n",
    "\n",
    "        # concat to get full address to the image\n",
    "        img_url = urljoin(url, img_url)\n",
    "        # remove error-prone http get kvey-values in the url\n",
    "        try:\n",
    "            pos = img_url.index(\"?\")\n",
    "            img_url = img_url[:pos]\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # check if img_url is valid and pass filter_func\n",
    "        if filter_func is not None and not filter_func(img_url, img_alt):\n",
    "            breakpoint()\n",
    "            print(f'{img_url} does not pass the filter function') #todo: write to a log file\n",
    "            continue\n",
    "\n",
    "        # download img_url\n",
    "        lat, lng = '10', '11' # temp\n",
    "        suffix = Path(img_url).suffix\n",
    "        filename = create_filename(lat, lng, visit_idx, img_alt, suffix) #todo: should includ image format/suffix. e.g.: '{lat}-{lon}-{direction}.png'\n",
    "        print('Downlaoding: ', img_url)\n",
    "        download(img_url, out_dir, filename)\n",
    "        \n",
    "        # collect all img_urls\n",
    "        img_urls.append(img_url)\n",
    "        if verbose:\n",
    "            print(f'\\n {img_url}')\n",
    "    \n",
    "            \n",
    "    return img_urls\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73392a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a valid img_url\n",
    "def is_valid_img_url(img_url: str, img_alt: str) -> bool:\n",
    "\n",
    "    # conditions to meet\n",
    "    meets_cond1 = is_valid(img_url)\n",
    "    meets_cond2 = '.gif' not in img_url.lower()\n",
    "    meets_cond3 = 'gps' not in img_alt.lower()\n",
    "    \n",
    "    return meets_cond1 and meets_cond2 and meets_cond3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "382eb91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://confluence.org/graphics/earthsmall2.gif does not pass the filter function\n",
      "Downlaoding:  https://confluence.org/ru/all/n53e051v2/%70%69%63%31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading temp/10-11-south-view.jpg:  32%|███▏      | 181k/560k [00:00<00:01, 269kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " https://confluence.org/ru/all/n53e051v2/%70%69%63%31.jpg\n",
      "Downlaoding:  https://confluence.org/ru/all/n53e051v2/%70%69%63%32.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading temp/10-11-west-view.jpg:   0%|          | 0.00/545k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading temp/10-11-west-view.jpg:   4%|▎         | 20.0k/545k [00:00<00:02, 204kB/s]\u001b[A\n",
      "Downloading temp/10-11-west-view.jpg:  33%|███▎      | 178k/545k [00:00<00:01, 273kB/s] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " https://confluence.org/ru/all/n53e051v2/%70%69%63%32.jpg\n",
      "Downlaoding:  https://confluence.org/ru/all/n53e051v2/%70%69%63%33.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloading temp/10-11-north-view.jpg:   0%|          | 0.00/433k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading temp/10-11-north-view.jpg:   6%|▌         | 24.0k/433k [00:00<00:02, 207kB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading temp/10-11-north-view.jpg:  42%|████▏     | 182k/433k [00:00<00:00, 280kB/s] \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " https://confluence.org/ru/all/n53e051v2/%70%69%63%33.jpg\n",
      "Downlaoding:  https://confluence.org/ru/all/n53e051v2/%70%69%63%34.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Downloading temp/10-11-east-view.jpg:   0%|          | 0.00/483k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading temp/10-11-east-view.jpg:   6%|▌         | 28.0k/483k [00:00<00:01, 287kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading temp/10-11-east-view.jpg:  37%|███▋      | 178k/483k [00:00<00:00, 373kB/s] \u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " https://confluence.org/ru/all/n53e051v2/%70%69%63%34.jpg\n",
      "https://confluence.org/ru/all/n53e051v2/%70%69%63%35.jpg does not pass the filter function\n",
      "Downlaoding:  https://confluence.org/ru/all/n53e051v2/%70%69%63%36.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading temp/10-11-hunter.jpg:   0%|          | 0.00/517k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading temp/10-11-hunter.jpg:   4%|▍         | 23.0k/517k [00:00<00:02, 197kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading temp/10-11-hunter.jpg:  35%|███▍      | 181k/517k [00:00<00:01, 267kB/s] \u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " https://confluence.org/ru/all/n53e051v2/%70%69%63%36.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://confluence.org/ru/all/n53e051v2/%70%69%63%31.jpg',\n",
       " 'https://confluence.org/ru/all/n53e051v2/%70%69%63%32.jpg',\n",
       " 'https://confluence.org/ru/all/n53e051v2/%70%69%63%33.jpg',\n",
       " 'https://confluence.org/ru/all/n53e051v2/%70%69%63%34.jpg',\n",
       " 'https://confluence.org/ru/all/n53e051v2/%70%69%63%36.jpg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test:\n",
    "url = 'https://confluence.org/photo.php?visitid=22761&pic=ALL'\n",
    "download_imgs(url, out_dir=Path('./temp'), filter_func=is_valid_img_url, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8556a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
